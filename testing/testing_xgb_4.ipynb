{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change the np.load to include the file\n",
    "- Add the following .pkl files into the same folder as this .ipynb (model, model_features, scaler, poly)\n",
    "- Edit the transform_features() method if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZrJYQUWBRE8",
    "outputId": "0992887d-734b-47ee-e5f7-72badc38ad9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user IDs in the test set: 1100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "import joblib\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "test=np.load(\"../datasets/labeled/fourth_batch_multi_labels.npz\")\n",
    "\n",
    "X_test=test[\"X\"]\n",
    "\n",
    "XX_test = pd.DataFrame(X_test)\n",
    "XX_test.rename(columns={0:\"user\",1:\"item\",2:\"rating\"},inplace=True)\n",
    "\n",
    "num_unique_users = XX_test[\"user\"].nunique()\n",
    "print(f\"Number of unique user IDs in the test set: {num_unique_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRt-PQQ4Biv6",
    "outputId": "6a93053f-949f-462c-ff0e-5bce3e2fa995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_features before selecting features (1100, 86)\n",
      "test_features after selecting features (1100, 54)\n",
      "Index(['review_count', 'avg_rating', 'std_rating', 'like_count',\n",
      "       'dislike_count', 'neutral_count', 'dislike_pct', 'unknown_pct',\n",
      "       'neutral_pct', 'rating_entropy', 'rare_movies_watched_pct',\n",
      "       'avg_movie_popularity', 'std_movie_popularity', 'min_movie_popularity',\n",
      "       'max_movie_popularity', 'std_deviation', 'mean_abs_deviation',\n",
      "       'max_abs_deviation', 'mean_rating_diff', 'std_rating_diff',\n",
      "       'max_abs_rating_diff', 'rating_changes_pct', 'z_rating_max',\n",
      "       'z_rating_median', 'z_rating_skew', 'likes_popular', 'likes_rare',\n",
      "       'dislikes_popular', 'dislikes_rare', 'neutral_popular', 'neutral_rare',\n",
      "       'unknown_popular', 'unknown_rare', 'interaction_entropy',\n",
      "       'like_dislike_ratio', 'popularity_vs_deviation', 'min_movie',\n",
      "       'max_movie', 'median_movie', 'variance_movie', 'sum_item_rating',\n",
      "       'average_product', 'product_above_zero', 'sum_above_zero',\n",
      "       'avg_product_vs_avg_rating', 'gap_mean', 'gap_max',\n",
      "       'user_pop_percentile_std', 'mean_item_rating_mean',\n",
      "       'std_item_rating_mean', 'mean_item_rating_median', 'popularity_skew',\n",
      "       'switch_pct', 'dominant_rating'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juski\\anaconda3\\envs\\CS421\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape (1100, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587442</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.209660</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.176878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995239</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992334</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990679</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.001775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  0.587442  0.010176  0.209660  0.000645  0.015200  0.176878\n",
       "1  0.999449  0.000066  0.000057  0.000009  0.000123  0.000296\n",
       "2  0.995239  0.000532  0.000428  0.000227  0.002767  0.000807\n",
       "3  0.992334  0.002720  0.000934  0.000073  0.001625  0.002314\n",
       "4  0.990679  0.001704  0.001187  0.001509  0.003145  0.001775"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.feature_transformation import aggregate_features\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "test_features = aggregate_features(XX_test)\n",
    "\n",
    "# TODO: To achieve the best result, need to select the best features based on SHAP. Just uncomment this code to get the highest AUC so far.\n",
    "# keep = set([\n",
    "#     \"user\",  # Keep user/label for merging\n",
    "\n",
    "#     # Existing SHAP-important features\n",
    "#     \"variance_movie\", \"sum_item_rating\", \"z_rating_max\", \"likes_rare\", \"gap_mean\", \"max_movie_popularity\", \"max_movie\", \"rare_like_ratio\", \"gap_max\", \"rare_movies_watched_pct\",\n",
    "#     \"std_deviation\", \"user_pop_percentile_std\", \"like_dislike_ratio\", \"unknown_pct\", \"average_product\", \"mean_abs_deviation\", \"popularity_vs_deviation\",\n",
    "#     \"rating_entropy\",\"std_movie_popularity\",\"mean_rating_diff\", \"median_movie\", \"max_abs_deviation\",\"min_movie_popularity\",\n",
    "#     \"z_rating_median\",\"dislike_pct\",\"popularity_vs_deviation\",\"avg_rating\",\n",
    "#     \"std_rating\",\"min_movie\",\n",
    "#     \"max_abs_rating_diff\",\n",
    "# ])\n",
    "# test_features = test_features[[col for col in test_features.columns if col in keep]]\n",
    "\n",
    "test_features.sort_values(by=\"user\", inplace=True)\n",
    "\n",
    "# Select only important features\n",
    "model_features = joblib.load(\"model_features.pkl\")\n",
    "print(f\"test_features before selecting features {test_features.shape}\")\n",
    "\n",
    "# If feature does not exist, populate with 0s\n",
    "for feat in model_features:\n",
    "    if feat not in test_features.columns:\n",
    "        test_features[feat] = 0\n",
    "test_features = test_features[model_features]\n",
    "print(f\"test_features after selecting features {test_features.shape}\")\n",
    "\n",
    "# debugging\n",
    "print(test_features.columns)\n",
    "\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "poly = joblib.load(\"poly.pkl\")\n",
    "\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "test_features_poly = poly.transform(test_features_scaled)\n",
    "\n",
    "# Load the trained model and predict probabilities (shape: #test_users x 6)\n",
    "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
    "probabilities = xgb_model.predict_proba(test_features_poly)\n",
    "y_pred_proba_rf = xgb_model.predict_proba(test_features_poly)\n",
    "# print(y_pred_proba_rf)\n",
    "\n",
    "np.savez(\"predictions.npz\", probabilities=probabilities)\n",
    "print(f\"prediction shape {probabilities.shape}\")\n",
    "\n",
    "test_results=np.load(\"predictions.npz\")\n",
    "test_results_df = pd.DataFrame(test_results[\"probabilities\"])\n",
    "test_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class instance counts:\n",
      "Class 0: 1062\n",
      "Class 1: 1\n",
      "Class 2: 2\n",
      "Class 3: 12\n",
      "Class 4: 13\n",
      "Class 5: 10\n"
     ]
    }
   ],
   "source": [
    "data = np.load('predictions.npz')\n",
    "predictions = data['probabilities']\n",
    "\n",
    "class_counts = {i: 0 for i in range(6)}\n",
    "\n",
    "for row in predictions:\n",
    "    predicted_class = np.argmax(row)\n",
    "    class_counts[predicted_class] += 1\n",
    "\n",
    "print(\"Class instance counts:\")\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f\"Class {class_label}: {count}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 0: AUC = 0.934\n",
      "  Class 1: AUC = 0.829\n",
      "  Class 2: AUC = 0.913\n",
      "  Class 3: AUC = 0.971\n",
      "  Class 4: AUC = 0.950\n",
      "  Class 5: AUC = 0.899\n",
      "\n",
      "üèÜ Final Evaluation Metric: 0.923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = test[\"y\"]\n",
    "\n",
    "# Convert true labels to a DataFrame\n",
    "df_y_true = pd.DataFrame(y_true, columns=[\"user\", \"true_label\"])\n",
    "\n",
    "# Load the predicted probabilities\n",
    "predictions_data = np.load(\"predictions.npz\")\n",
    "probabilities = predictions_data[\"probabilities\"]\n",
    "\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    \"user\": df_y_true[\"user\"],\n",
    "    \"true_label\": df_y_true[\"true_label\"],\n",
    "    \"predicted_label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Identify misclassified users\n",
    "df_predictions[\"correct\"] = df_predictions[\"true_label\"] == df_predictions[\"predicted_label\"]\n",
    "df_misclassified = df_predictions[df_predictions[\"correct\"] == False]\n",
    "# df_misclassified.head(2)\n",
    "# df_misclassified.to_csv(\"misclassified_users.csv\", index=False)\n",
    "\n",
    "auc_per_class = {}\n",
    "for i in range(probabilities.shape[1]):\n",
    "    binary_true = (df_predictions[\"true_label\"] == i).astype(int)\n",
    "    try:\n",
    "        auc = roc_auc_score(binary_true, probabilities[:, i])\n",
    "        auc_per_class[i] = auc\n",
    "        print(f\"  Class {i}: AUC = {auc:.3f}\")\n",
    "    except ValueError:\n",
    "        auc_per_class[i] = None\n",
    "\n",
    "k = 5\n",
    "AUC_0 = auc_per_class[0]\n",
    "anomaly_aucs = [auc_per_class[i] for i in range(1, k+1) if i in auc_per_class]\n",
    "\n",
    "final_metric = (0.5 * AUC_0) + (0.5 / k) * sum(anomaly_aucs)\n",
    "print(f\"\\nüèÜ Final Evaluation Metric: {final_metric:.3f}\")\n",
    "\n",
    "# Convert AUC scores to DataFrame\n",
    "df_auc = pd.DataFrame(list(auc_per_class.items()), columns=[\"class\", \"AUC\"])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CS421",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
