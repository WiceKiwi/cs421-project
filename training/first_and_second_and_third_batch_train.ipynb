{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M196SD4NSQ-f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from scipy.stats import entropy\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))\n",
        "\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "data=np.load(\"../datasets/labeled/first_batch_multi_labels.npz\")\n",
        "data2=np.load(\"../datasets/labeled/second_batch_multi_labels.npz\")\n",
        "data3=np.load(\"../datasets/labeled/third_batch_multi_labels.npz\")\n",
        "\n",
        "X1=data[\"X\"]\n",
        "y1=data[\"y\"]\n",
        "\n",
        "X2=data2[\"X\"]\n",
        "y2=data2[\"y\"]\n",
        "\n",
        "X3=data3[\"X\"]\n",
        "y3=data3[\"y\"]\n",
        "\n",
        "X=np.concatenate((X1,X2,X3),axis=0)\n",
        "y=np.concatenate((y1,y2,y3),axis=0)\n",
        "\n",
        "XX=pd.DataFrame(X)\n",
        "yy=pd.DataFrame(y)\n",
        "XX.rename(columns={0:\"user\",1:\"item\",2:\"rating\"},inplace=True)\n",
        "yy.rename(columns={0:\"user\",1:\"label\"},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9v8FjBSS_8",
        "outputId": "2ce2a1f8-eb6e-4685-cf56-25bd3823acac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(524883, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  item  rating  label\n",
              "0     0     9       0      0\n",
              "1     0    12      10      0\n",
              "2     0    13      10      0\n",
              "3     0    15      10      0\n",
              "4     0    16       1      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge labels into main dataset\n",
        "XX = XX.merge(yy, on=\"user\", how=\"left\").sort_values(by=[\"user\", \"item\"]).reset_index(drop=True)\n",
        "\n",
        "print(XX.shape)\n",
        "XX.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bsN5fp2JSWY9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3300, 87)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>review_count</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>std_rating</th>\n",
              "      <th>like_count</th>\n",
              "      <th>dislike_count</th>\n",
              "      <th>unknown_count</th>\n",
              "      <th>neutral_count</th>\n",
              "      <th>like_pct</th>\n",
              "      <th>dislike_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>item_mean_vs_user_avg</th>\n",
              "      <th>item_skew_bias</th>\n",
              "      <th>normalized_movie_popularity</th>\n",
              "      <th>popularity_skew</th>\n",
              "      <th>rating_polarity</th>\n",
              "      <th>activity_weighted_skew</th>\n",
              "      <th>switch_pct</th>\n",
              "      <th>dominant_rating</th>\n",
              "      <th>dominance_ratio</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>5.946429</td>\n",
              "      <td>5.253181</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>49</td>\n",
              "      <td>14</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.029762</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.066024</td>\n",
              "      <td>-0.437554</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2282</td>\n",
              "      <td>0.565476</td>\n",
              "      <td>-2.817185</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>10</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>208</td>\n",
              "      <td>3.158654</td>\n",
              "      <td>5.890205</td>\n",
              "      <td>76</td>\n",
              "      <td>16</td>\n",
              "      <td>57</td>\n",
              "      <td>59</td>\n",
              "      <td>0.365385</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082865</td>\n",
              "      <td>-0.454684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2333</td>\n",
              "      <td>0.288462</td>\n",
              "      <td>-1.703270</td>\n",
              "      <td>0.740385</td>\n",
              "      <td>10</td>\n",
              "      <td>0.365385</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>195</td>\n",
              "      <td>1.025641</td>\n",
              "      <td>7.750913</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>0.338462</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>...</td>\n",
              "      <td>1.954071</td>\n",
              "      <td>-0.449163</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2294</td>\n",
              "      <td>0.071795</td>\n",
              "      <td>-1.356825</td>\n",
              "      <td>0.805128</td>\n",
              "      <td>10</td>\n",
              "      <td>0.338462</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>1.073171</td>\n",
              "      <td>6.455193</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>...</td>\n",
              "      <td>2.567873</td>\n",
              "      <td>-0.533277</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1990</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>-0.522866</td>\n",
              "      <td>0.634146</td>\n",
              "      <td>1</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6.833333</td>\n",
              "      <td>4.915960</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.739258</td>\n",
              "      <td>-0.500907</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1578</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-1.449192</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>10</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 87 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  review_count  avg_rating  std_rating  like_count  dislike_count  \\\n",
              "0     0           168    5.946429    5.253181         100              5   \n",
              "1     1           208    3.158654    5.890205          76             16   \n",
              "2     2           195    1.025641    7.750913          66             52   \n",
              "3     3            41    1.073171    6.455193          10              7   \n",
              "4     4             6    6.833333    4.915960           4              0   \n",
              "\n",
              "   unknown_count  neutral_count  like_pct  dislike_pct  ...  \\\n",
              "0             49             14  0.595238     0.029762  ...   \n",
              "1             57             59  0.365385     0.076923  ...   \n",
              "2             60             17  0.338462     0.266667  ...   \n",
              "3             14             10  0.243902     0.170732  ...   \n",
              "4              1              1  0.666667     0.000000  ...   \n",
              "\n",
              "   item_mean_vs_user_avg  item_skew_bias  normalized_movie_popularity  \\\n",
              "0              -3.066024       -0.437554                          1.0   \n",
              "1              -0.082865       -0.454684                          1.0   \n",
              "2               1.954071       -0.449163                          1.0   \n",
              "3               2.567873       -0.533277                          1.0   \n",
              "4              -3.739258       -0.500907                          1.0   \n",
              "\n",
              "   popularity_skew  rating_polarity  activity_weighted_skew  switch_pct  \\\n",
              "0             2282         0.565476               -2.817185    0.714286   \n",
              "1             2333         0.288462               -1.703270    0.740385   \n",
              "2             2294         0.071795               -1.356825    0.805128   \n",
              "3             1990         0.073171               -0.522866    0.634146   \n",
              "4             1578         0.666667               -1.449192    0.833333   \n",
              "\n",
              "   dominant_rating  dominance_ratio  label  \n",
              "0               10         0.595238      0  \n",
              "1               10         0.365385      0  \n",
              "2               10         0.338462      3  \n",
              "3                1         0.341463      0  \n",
              "4               10         0.666667      0  \n",
              "\n",
              "[5 rows x 87 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from utils.feature_transformation import aggregate_features\n",
        "\n",
        "user_features = aggregate_features(XX)\n",
        "user_features = user_features.merge(yy, on=\"user\", how=\"left\")\n",
        "print(user_features.shape)\n",
        "# user_features.to_csv(\"user_features.csv\", index=False)\n",
        "user_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "7VKt4RkVSYIh",
        "outputId": "fef9626a-74d2-484a-cedb-a2c2fc60813b"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "df = user_features.copy()\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "dIjaIB91SbZy",
        "outputId": "baab7aeb-0742-48ba-d83c-7c3cb8bbb4f6"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=[\"user\"], inplace=True)\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TmQ09yYScyW",
        "outputId": "d5589bcf-a3d0-4814-c939-1b92b7d359c7"
      },
      "outputs": [],
      "source": [
        "correlated_features = set()\n",
        "threshold = 0.9\n",
        "\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
        "            colname = correlation_matrix.columns[i]\n",
        "            correlated_features.add(colname)\n",
        "\n",
        "df.drop(columns=correlated_features, inplace=True, errors=\"ignore\")\n",
        "print(f\"Dropped correlated features: {correlated_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "G1HMkMJiSfBZ",
        "outputId": "f05906c2-a272-4e8d-c39e-7a6f049a54a3"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "vEBCy3V3SgrV",
        "outputId": "c1b8bd5b-3149-4d69-ecb2-0fbc634d4fc6"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "print(X.columns)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPTpSwrMSkF_",
        "outputId": "17c78c6a-6e05-413d-edce-5dcbba40df2f"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "print(\"🔹 Original Class Distribution:\", Counter(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=SEED)\n",
        "\n",
        "smote = SMOTE(sampling_strategy='not majority', random_state=SEED)\n",
        "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
        "print(\"🔹 Distribution after SMOTE (only minority oversampled):\", Counter(y_train_over))\n",
        "\n",
        "tomek = TomekLinks(sampling_strategy='not majority')\n",
        "X_train_resampled, y_train_resampled = tomek.fit_resample(X_train_over, y_train_over)\n",
        "print(\"🔹 Final Resampled Distribution (After applying Tomek on minority):\", Counter(y_train_resampled))\n",
        "\n",
        "# smote_tomek = SMOTETomek(random_state=SEED)\n",
        "# X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "# class_distribution = Counter(y_train_resampled)\n",
        "# print(\"🔹 Resampled Class Distribution (After SMOTE):\", class_distribution)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# poly = PolynomialFeatures(degree=1, interaction_only=False, include_bias=False)\n",
        "# X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "# X_test_poly = poly.transform(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "import json\n",
        "\n",
        "params_file = \"best_xgb_params.json\"\n",
        "\n",
        "if os.path.exists(params_file):\n",
        "    print(\"Hyperparameters found.\")\n",
        "    with open(params_file, \"r\") as f:\n",
        "        best_params = json.load(f)\n",
        "else:\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            \"objective\": \"multi:softprob\",\n",
        "            \"num_class\": len(np.unique(y_train_resampled)),\n",
        "            \"eval_metric\": \"mlogloss\",\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
        "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "            \"gamma\": trial.suggest_float(\"gamma\", 0, 0.2),\n",
        "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True),\n",
        "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True),\n",
        "            \"random_state\": SEED,\n",
        "            \"tree_method\": \"exact\",\n",
        "            \"predictor\": \"cpu_predictor\",\n",
        "            \"verbosity\": 0,\n",
        "            \"n_jobs\": 1\n",
        "        }\n",
        "\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(X_train_scaled, y_train_resampled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "        auc_scores = []\n",
        "        for i in range(y_pred_proba.shape[1]):\n",
        "            binary_true = (y_test == i).astype(int)\n",
        "            try:\n",
        "                auc = roc_auc_score(binary_true, y_pred_proba[:, i])\n",
        "                auc_scores.append(auc)\n",
        "            except:\n",
        "                auc_scores.append(0)\n",
        "\n",
        "        return np.mean(auc_scores)\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=80)\n",
        "\n",
        "    best_params = study.best_params\n",
        "\n",
        "    with open(params_file, \"w\") as f:\n",
        "        json.dump(best_params, f)\n",
        "\n",
        "    print(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num_classes = len(np.unique(y))\n",
        "# xgb_model = xgb.XGBClassifier(\n",
        "#     **best_params,\n",
        "#     objective='multi:softprob',\n",
        "#     num_class=num_classes,\n",
        "#     eval_metric='mlogloss',\n",
        "#     random_state=SEED,\n",
        "#     reg_lambda=0.1,\n",
        "#     n_jobs=1,\n",
        "# )\n",
        "\n",
        "# xgb_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# y_pred_proba_xgb = xgb_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# print(\"XGBoost AUC Scores per Class:\")\n",
        "# auc_per_class_xgb = {}\n",
        "# for i in range(y_pred_proba_xgb.shape[1]):\n",
        "#     binary_true = (y_test == i).astype(int)\n",
        "#     try:\n",
        "#         auc = roc_auc_score(binary_true, y_pred_proba_xgb[:, i])\n",
        "#         auc_per_class_xgb[i] = auc\n",
        "#         print(f\"  Class {i}: AUC = {auc:.3f}\")\n",
        "#     except Exception as e:\n",
        "#         auc_per_class_xgb[i] = None\n",
        "#         print(f\"  Class {i}: AUC could not be computed\")\n",
        "\n",
        "# k = 5\n",
        "# AUC_0 = auc_per_class_xgb[0]\n",
        "# anomaly_aucs = [auc_per_class_xgb[i] for i in range(1, k+1) if i in auc_per_class_xgb]\n",
        "\n",
        "# final_metric = (0.5 * AUC_0) + (0.5 / k) * sum(anomaly_aucs)\n",
        "\n",
        "# print(f\"\\nFinal Evaluation Metric: {final_metric:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import xgboost as xgb\n",
        "\n",
        "model_features = list(X_train.columns)\n",
        "\n",
        "# Combine train and test\n",
        "X_full = np.concatenate((X_train, X_test), axis=0)\n",
        "y_full = np.concatenate((y_train, y_test), axis=0)\n",
        "print(\"🔹 Original Class Distribution (Full Dataset):\", Counter(y_full))\n",
        "\n",
        "# Step 1: Oversample only minority classes (labels 1-5) to match class 0 using SMOTE.\n",
        "# Setting sampling_strategy='not majority' means only classes other than the majority are oversampled.\n",
        "smote = SMOTE(sampling_strategy='not majority', random_state=SEED)\n",
        "X_over, y_over = smote.fit_resample(X_full, y_full)\n",
        "print(\"🔹 Distribution after SMOTE (only minority oversampled):\", Counter(y_over))\n",
        "\n",
        "tomek = TomekLinks(sampling_strategy='not majority')\n",
        "X_resampled, y_resampled = tomek.fit_resample(X_over, y_over)\n",
        "print(\"🔹 Final Resampled Distribution (After applying Tomek on minority):\", Counter(y_resampled))\n",
        "\n",
        "# Preprocess and train the model\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(pd.DataFrame(X_resampled, columns=model_features))\n",
        "\n",
        "num_classes = len(np.unique(y_full))\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    objective='multi:softprob',\n",
        "    num_class=num_classes,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=SEED,\n",
        "    reg_lambda=0.1,\n",
        "    n_jobs=1,\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_scaled, y_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save objects\n",
        "joblib.dump(model_features, \"../testing/model_features.pkl\")\n",
        "joblib.dump(scaler, \"../testing/scaler.pkl\")\n",
        "joblib.dump(xgb_model, \"../testing/xgb_model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import shap\n",
        "\n",
        "# explainer = shap.TreeExplainer(xgb_model, X_train_scaled)\n",
        "# shap_values = explainer(X_test_scaled[:100], check_additivity=False)\n",
        "\n",
        "# shap_array = shap_values.values  # shape: (n_samples, n_features, n_classes)\n",
        "\n",
        "# # Loop over classes and show SHAP summary\n",
        "# for class_id in range(num_classes):\n",
        "#     print(f\"\\n📊 SHAP Summary for Class {class_id}\")\n",
        "#     shap.summary_plot(\n",
        "#         shap_array[:, :, class_id],  # SHAP values for this class\n",
        "#         X_test_scaled[:100],\n",
        "#         feature_names=model_features,\n",
        "#         show=True\n",
        "#     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if isinstance(X_test_scaled, np.ndarray):\n",
        "#     X_test_scaled = pd.DataFrame(X_test_scaled, columns=model_features)\n",
        "\n",
        "# for class_id in range(num_classes):\n",
        "#     print(f\"\\n🧠 SHAP Decision Plot for Class {class_id}\")\n",
        "    \n",
        "#     shap.decision_plot(\n",
        "#         explainer.expected_value[class_id],\n",
        "#         shap_array[:10, :, class_id],\n",
        "#         X_test_scaled.iloc[:10],\n",
        "#         feature_names=model_features,\n",
        "#         show=True\n",
        "#     )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CS421",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
